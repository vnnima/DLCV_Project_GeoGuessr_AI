{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e245fce4-158d-4af1-974f-612a6d9f412a",
   "metadata": {},
   "source": [
    "# Train Some Example Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce346822-91eb-4445-bea6-12cf0e7d23d8",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d29667e-24d9-4b38-9838-aafd30f57212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.getcwd()\n",
    "sys.path.append('../preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b61996-c644-4ecc-af5c-05e45d8a18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "# Dataset\n",
    "# from preprocess.GeoGuessrDataset import GeoGuessrDataset\n",
    "from GeoGuessrDataset import GeoGuessrDataset, ToTensor\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable autoreloading of imported modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c32ddae-5902-43d5-a859-ed076a6cfbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU support on your machine.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "root_dir = r\"C:\\Users\\Shadow\\Pictures\\Geogussr\\Projekt\"\n",
    "HEIGHT = 512\n",
    "WIDTH = 2560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b5525b-9190-447e-bf88-0adcf39c4ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A4500'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6895015f-4029-41f5-b652-5981a984281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GeoGuessrNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeoGuessrNet, self).__init__()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=16, stride=6, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=16, stride=6, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=8, stride=6, padding=1)\n",
    "        \n",
    "        # Define the fully-connected layers\n",
    "        self.fc1 = nn.Linear(704, 200)  # modified to have the correct input size\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        self.fc3 = nn.Linear(10, 32768)\n",
    "        # self.fc2 = nn.Linear(1024, 32768)  # output size is still 32768\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x) \n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2dab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capacity(module):\n",
    "    \"\"\"\n",
    "    Computes the number of learnable parameters.\n",
    "\n",
    "    Parameters:\n",
    "        - module (nn.Module): Module with parameters.\n",
    "\n",
    "    Returns:\n",
    "        - num_param (int): Number of parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    num_param = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "    return num_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3608cf99-d7f6-4e5d-8839-0796f28ecec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47483024\n"
     ]
    }
   ],
   "source": [
    "from networks import ResNet\n",
    "from networks import ResNet2\n",
    "from networks import TraversedNet\n",
    "#model_1 = GeoGuessrNet()\n",
    "#model_2 = ResNet()\n",
    "#model_3 = ResNet2()\n",
    "model_4 = TraversedNet()\n",
    "model = model_4.to(device)\n",
    "#summary(model, (3,HEIGHT, WIDTH))\n",
    "print(capacity(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f11b1f-9dd6-4f86-8f24-2df4d967ecdf",
   "metadata": {},
   "source": [
    "### Define Model and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f103995-6fe0-4ae2-9750-56c9d73aa223",
   "metadata": {},
   "source": [
    "### Define Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314633cb-4f2a-4dde-96c7-af233de9b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "# Define the data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fbb524-552f-442e-9be5-7806ff6d5f2d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "582da5fa-586a-4b5b-a7ff-72f74828a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and split it into training and validation sets\n",
    "# You will need to implement the `GeoLocDataset` class and the `__getitem__` and `__len__` methods\n",
    "\n",
    "dataset = GeoGuessrDataset(csv_file='../preprocess/coordinates_geohash.csv',\n",
    "                                    root_dir=root_dir, transform=transform)\n",
    "train_size = int(0.95 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Define the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=7,pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=7,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3539782-ebf4-4d6b-8655-1fd3e76cc227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 512, 2560]) torch.Size([8, 32768])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    x, y = batch[\"image\"], batch[\"geohash\"]\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b4ff7-fc22-4b59-9358-f611d914d8f7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80cafde-81a4-4e86-81fc-8e7078f7ebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c39b57-2075-4562-9bae-767638476d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043b016d69144adca1a27c81ffae0f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "accum_iter = 4\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "best_loss= 10\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "for epoch in (pbar := tnrange(num_epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    #for idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "    # Convert images (input) to float because it is a ByteTensor. Why is it a ByteTensor?\n",
    "    images, labels = batch[\"image\"].float(), batch[\"geohash\"].float()\n",
    "    #if idx % 1000 == 0:\n",
    "     #   print(idx)\n",
    "    # Move the data to the device\n",
    "    images = images.to(device,non_blocking=True)\n",
    "    labels = labels.to(device,non_blocking=True)\n",
    "\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        assert outputs.dtype is torch.float16\n",
    "        loss = criterion(outputs, labels)\n",
    "        assert loss.dtype is torch.float32\n",
    "\n",
    "    # Backward pass\n",
    "    scaler.scale(loss).backward()\n",
    "    #increase effective batch size and have more stable gradients\n",
    "    #if ((idx + 1) % accum_iter == 0) or (idx + 1 == len(train_dataloader)):\n",
    "        # Update the weights\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Accumulate the training loss\n",
    "    train_loss += loss.item() \n",
    "    train_loss = train_loss / 1\n",
    "        \n",
    "        #print(train_loss, best_loss)\n",
    "    #if train_loss < best_loss:\n",
    "     #   best_loss = train_loss\n",
    "      #  PATH3 = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\models\\TraversedNet_best.tar\"\n",
    "       # torch.save({\n",
    "        #'epoch': epoch,\n",
    "        #'model_state_dict': model.state_dict(),\n",
    "        #'optimizer_state_dict': optimizer.state_dict(),\n",
    "       # 'loss': loss\n",
    "       # }, PATH3)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    pbar.set_description(f'Epoch: {epoch + 1}  Loss: {train_loss:.5f}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7db2f",
   "metadata": {},
   "source": [
    "### Saving (change name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0872a90-4a8e-4cc8-9e35-7b9643912592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH1 = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\models\\TraversedNetmodel.pt\"\n",
    "#PATH2 = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\models\\TraversedNetoptim.pt\"\n",
    "#torch.save(model.state_dict(), PATH1)\n",
    "#torch.save(optimizer.state_dict(), PATH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7222c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH3 = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\models\\TraversedNet_best.tar\"\n",
    "#torch.save({\n",
    " #           'epoch': epoch,\n",
    "  #          'model_state_dict': model.state_dict(),\n",
    "   #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #        'loss': loss\n",
    "     #       }, PATH3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03028b18",
   "metadata": {},
   "source": [
    "### Load Model State (change Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0daf5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "checkpoint = torch.load(r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\models\\TraversedNet_best.tar\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c0e7f-c668-450e-a4ed-419e84a7d954",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f862ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeohash\n",
    "def decimal_to_geohash(decimal):\n",
    "    base_32 = '0123456789bcdefghjkmnpqrstuvwxyz'\n",
    "    geohash = ''\n",
    "    while decimal > 0:\n",
    "        geohash += base_32[decimal % 32]\n",
    "        decimal //= 32\n",
    "    return geohash[::-1]\n",
    "\n",
    "def geohash_to_lat_lon(geohash):\n",
    "    return pygeohash.decode(geohash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180f6280-9f8d-4ff7-94fd-8ef66233a19b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 290, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-valdrin\\model\\GeoGuessrDataset.py\", line 48, in __getitem__\n    sample[\"image\"] = self.transform(sample[\"image\"])\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 94, in __call__\n    img = t(img)\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 134, in __call__\n    return F.to_tensor(pic)\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 153, in to_tensor\n    return img.to(dtype=default_float_dtype).div(255)\nRuntimeError: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 15728640 bytes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, batch  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataloader):\n\u001b[0;32m     13\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat(), batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeohash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# Move the data to the device\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1402\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 290, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-valdrin\\model\\GeoGuessrDataset.py\", line 48, in __getitem__\n    sample[\"image\"] = self.transform(sample[\"image\"])\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 94, in __call__\n    img = t(img)\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 134, in __call__\n    return F.to_tensor(pic)\n  File \"C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 153, in to_tensor\n    return img.to(dtype=default_float_dtype).div(255)\nRuntimeError: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 15728640 bytes.\n"
     ]
    }
   ],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "###########################\n",
    "geogussrscore = []\n",
    "###########################\n",
    "# Validation\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for idx, batch  in enumerate(val_dataloader):\n",
    "        images, labels = batch[\"image\"].float(), batch[\"geohash\"].float()\n",
    "        # Move the data to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        prediction = torch.argmax(outputs.data, 1)\n",
    "        labels = torch.argmax(labels.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        \n",
    "        # Accumulate the validation loss                                \n",
    "        val_loss += loss.item() * images.size(0)                        \n",
    "        \n",
    "        \n",
    "        #################distance\n",
    "        distance = []\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            distance.append(haversine(geohash_to_lat_lon(decimal_to_geohash(prediction.data[i])),geohash_to_lat_lon(decimal_to_geohash(labels.data[i]))))\n",
    "            #geohashes_pred.append(geohash_to_lat_lon(decimal_to_geohash(prediction.data[i])))\n",
    "            #geohashes_label.append(geohash_to_lat_lon(decimal_to_geohash(labels.data[i])))\n",
    "        \n",
    "        \n",
    "        #distances = haversine(geohashes_pred, geohashes_label)\n",
    "        geogussrscore.append((5000*np.exp(-np.array(distance)/2000)).mean())\n",
    "        \n",
    "        \n",
    "        ##################################\n",
    "    #evaluate accuracy         \n",
    "accuracy = 100* correct/total\n",
    "\n",
    "# Print the epoch loss                                                  \n",
    "#train_loss = train_loss / len(train_dataloader.dataset)                 \n",
    "val_loss = val_loss / len(val_dataloader.dataset)\n",
    "average_score = np.array(geogussrscore).mean()\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436687ba-3e08-4793-91f4-b872bb484cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060011bb-bf64-4f29-a427-a0f79e049c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "5000*np.exp(-10/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9216d7-e663-4ff4-ae65-d45a67489ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282a8cb-2ed2-43f0-89db-0ef27af5968d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09843b78-56bb-4f0a-a925-22bb4f5d69a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce3674-f387-4f76-bd46-dd221d8cc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(10):\n",
    "    sample = dataset[i]\n",
    "    plt.imshow(sample[\"image\"].permute(1, 2, 0))\n",
    "    print(i, sample['image'].shape, sample['geohash'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f183a8-2c0b-4baf-8ae5-40acbcec10ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c6d33-12fb-430c-b851-18ce5c4d0256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c2acd-02b7-40d8-890a-0d9e836a1cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
