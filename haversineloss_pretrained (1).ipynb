{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ot7HwUXrbvLP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Uni/Deep Learning for Computer Vision/GeoGuessr_Project')\n",
    "\n",
    "# folder with pictures\n",
    "ROOT_DIR = r'C:\\Users\\Shadow\\Pictures\\Geogussr\\Projekt'\n",
    "\n",
    "# dir to csv files\n",
    "dir = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\preprocess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N6AFTTy1w6-f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "#from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "# Dataset\n",
    "from GeoGuessrDataset import GeoGuessrDataset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tnrange\n",
    "import time\n",
    "import copy\n",
    "import pygeohash as phg\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable autoreloading of imported modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1672146399703,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "kj2xe7ZMKAs1",
    "outputId": "c81c3968-51d1-486d-f131-b8a171b62bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check GPU support on your machine.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "HEIGHT = 512\n",
    "WIDTH = 2560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1672147666496,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "YZytNzAjKDPf",
    "outputId": "8f6445df-cf8e-4b70-b414-11a1a81a29fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models.resnet import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights\n",
    "\n",
    "\n",
    "# New weights with accuracy 80.858%\n",
    "resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Best available weights (currently alias for IMAGENET1K_V2)\n",
    "# Note that these weights may change across versions\n",
    "resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1672147548946,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "Ob0MqD7HjcOD",
    "outputId": "550af3e4-a0bd-4353-d812-5f8d04873fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of geohashes with samples 3139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(dir+\"\\coordinates.csv\", delimiter=',', skiprows=0, low_memory=False)\n",
    "\n",
    "# We want a geohash precsion of 3 so that we get approximately 32768 cells, which will represent our classes.\n",
    "df['geohash']=df.apply(lambda coords: phg.encode(coords.latitude, coords.longitude, precision=3), axis=1)\n",
    "\n",
    "\n",
    "def geohash_to_decimal(geohash):\n",
    "    base_32 = '0123456789bcdefghjkmnpqrstuvwxyz';\n",
    "    geohash = geohash.lower()\n",
    "    # Check that the input geohash is a valid geohash\n",
    "    if not all(c in base_32 for c in geohash):\n",
    "        raise ValueError('Invalid geohash')\n",
    "    return sum([32**idx * base_32.index(char) for idx, char in enumerate(geohash[::-1])])\n",
    "\n",
    "df['geohash_decimal']=df.apply(lambda x: geohash_to_decimal(x[\"geohash\"]) ,axis=1)\n",
    "\n",
    "geohashes_with_samples = df[\"geohash_decimal\"].unique()\n",
    "print(\"Number of geohashes with samples\", len(geohashes_with_samples))\n",
    "\n",
    "geohash_map = { geo: i for i, geo in enumerate(geohashes_with_samples)}\n",
    "\n",
    "df[\"geo_code\"] = df.apply(lambda geohash: geohash_map[geohash[\"geohash_decimal\"]], axis=1)\n",
    "\n",
    "df[[\"filename\", \"latitude\",\"longitude\", \"geohash_decimal\", \"geo_code\"]].to_csv(dir+\"\\coordinates2.csv\", index=False)\n",
    "\n",
    "# Add geohash center coordinates to csv\n",
    "\n",
    "def geohash_center(geohash_name):\n",
    "\n",
    "    # Decode the geohash to get the center coordinates and errors.\n",
    "    latitude, longitude, latitude_error, longitude_error = phg.decode_exactly(geohash_name)\n",
    "    return [latitude, longitude]\n",
    "\n",
    "df[\"geo_lat\"], df[\"geo_lon\"] = df.apply(lambda x: geohash_center(x[\"geohash\"])[0] ,axis=1), df.apply(lambda x: geohash_center(x[\"geohash\"])[1] ,axis=1)\n",
    "\n",
    "# drop the duplicates\n",
    "df = df.drop(columns=[\"filename\", \"latitude\", \"longitude\",\"geohash_decimal\",\"geohash\"] )\n",
    "df = df.drop_duplicates()\n",
    "array = df.to_numpy()\n",
    "array = np.array(array, dtype=np.float64)\n",
    "tensor = torch.tensor(array)\n",
    "torch.save(tensor, dir+'\\\\tensor.pt')\n",
    "# Save the DataFrame to a CSV file.\n",
    "df[[\"geo_code\", \"geo_lat\", \"geo_lon\"]].to_csv(dir+\"\\coords_center.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1672147587577,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "bE4hyeKWKELu",
    "outputId": "4309c3f8-60cc-4217-b5a5-0d1dffee53c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127474\n",
      "torch.Size([64, 3, 250, 1000]) torch.Size([64, 3139]) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "# Define the data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((250, 1000))\n",
    "])\n",
    "\n",
    "# Load the dataset and split it into training and validation sets\n",
    "dataset = GeoGuessrDataset(csv_file=dir+'\\coordinates2.csv',\n",
    "                                    root_dir=ROOT_DIR, transform=transform, num_classes=3139)\n",
    "train_size = int(0.99 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "print(len(train_dataset))\n",
    "# Define the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=6)\n",
    "\n",
    "dataloaders = {\"train\" : train_dataloader, \"val\": val_dataloader}\n",
    "dataset_sizes = {\"train\": train_size, \"val\" : val_size}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    x, y, z = batch[\"image\"], batch[\"geohash\"], batch['gt']\n",
    "    print(x.shape, y.shape, z.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3yX0Ph7LKEO7"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    batch=next(iter(dataloaders[\"train\"]))\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            #for idx, batch in enumerate(dataloaders[phase]):\n",
    "            inputs, labels, gt = batch[\"image\"], batch[\"geohash\"], batch['gt']\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                print(criterion2(outputs, gt))\n",
    "                loss = criterion(outputs, labels.float())\n",
    "\n",
    "                ######\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    optimizer.step()\n",
    "            _,labels = torch.max(labels, 1)\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            #print(preds)\n",
    "            #print(labels)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / 64 #dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / 64 #dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def haversine_loss(lons1, lats1, lons2, lats2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two sets of longitudes and latitudes.\n",
    "\n",
    "    Parameters:\n",
    "        - lons1 (torch.tensor): Tensor of longitudes for the first set of points.\n",
    "        - lats1 (torch.tensor): Tensor of latitudes for the first set of points.\n",
    "        - lons2 (torch.tensor): Tensor of longitudes for the second set of points.\n",
    "        - lats2 (torch.tensor): Tensor of latitudes\n",
    "\n",
    "    Returns:\n",
    "        - distances (torch.tensor): Tensor of Haversine distances.\n",
    "    \"\"\"\n",
    "    # Convert longitudes and latitudes to radians.\n",
    "    lons1 = lons1.to(torch.float) * math.pi / 180\n",
    "    lats1 = lats1.to(torch.float) * math.pi / 180\n",
    "    lons2 = lons2.to(torch.float) * math.pi / 180\n",
    "    lats2 = lats2.to(torch.float) * math.pi / 180\n",
    "\n",
    "    # Calculate differences in longitudes and latitudes.\n",
    "    dlons = lons2 - lons1\n",
    "    dlats = lats2 - lats1\n",
    "\n",
    "    # Calculate intermediate values.\n",
    "    a = (torch.sin(dlats / 2)**2) + (torch.cos(lats1) * torch.cos(lats2) * (torch.sin(dlons / 2)**2))\n",
    "    c = 2 * torch.atan2(torch.sqrt(a), torch.sqrt(1 - a))\n",
    "\n",
    "    # Calculate distances.\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    distances = R * c\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom loss that transforms the predicted cluster and the ground truth label into coordinates\n",
    "# and then computes the haversine distance between them as loss\n",
    "\n",
    "\n",
    "class HaversineLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HaversineLoss, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, output, gt):\n",
    "        \"\"\"\n",
    "            output: (batchsize, num_clusters) Tensor with probabillities\n",
    "            gt: tupel contains groundtruth lat, lon\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        tensor = torch.load(dir+'\\\\tensor.pt')\n",
    "        # Extract the latitude and longitude from the predicted location.\n",
    "        #lat_cluster, lon_cluster = torch.zeros(len(output)), torch.zeros(len(output))\n",
    "        lat_cluster, lon_cluster = tensor[:,1], tensor[:,2]\n",
    "\n",
    "        # Calculate the Haversine distance between the predicted and target locations.\n",
    "        gt0 = torch.tensor(gt[:,0])\n",
    "        gt1 = torch.tensor(gt[:,1])\n",
    "        \n",
    "        distance = haversine_loss(lat_cluster, lon_cluster, gt0[:,None], gt1[:,None])\n",
    "        #print(torch.argmin(distance,dim=1))    \n",
    "        \n",
    "        \n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        # Return the loss.\n",
    "        distance = distance.to(device)\n",
    "        print(torch.sum(distance*output,dim=1))\n",
    "        \n",
    "        loss = torch.mean(torch.sum(distance*output,dim=1))\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IVLjMMowKER4"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "# model_ft = models.resnet18()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3139)\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    " \n",
    "criterion2 = HaversineLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=200, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4792103,
     "status": "ok",
     "timestamp": 1672152510104,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "uPdTudKxnSoo",
    "outputId": "7f192f3b-35a2-495d-8033-6a2712be1716",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_18340\\3723925526.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt0 = torch.tensor(gt[:,0])\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_18340\\3723925526.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt1 = torch.tensor(gt[:,1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8317.4912,  9860.8545,  9227.1504,  9871.3789, 10257.8867,  9573.2607,\n",
      "         9469.5908,  9598.7998,  9193.7012, 10782.8867,  9328.4346,  8331.4355,\n",
      "         9217.6768,  8348.5127, 11070.0742,  8925.2998,  8348.4102,  8326.8252,\n",
      "        11138.6455, 10797.1172,  8393.9316, 11179.7344,  8342.4766,  9508.3477,\n",
      "         9135.6719,  8289.0859, 10986.9580, 10852.9805,  8394.6875, 10774.4688,\n",
      "         8513.6035,  9290.9180,  9340.1748, 10476.6416,  8767.4658,  9295.7988,\n",
      "        10970.9131, 10827.6953,  8324.3721,  9000.5586, 10725.6953,  8293.3779,\n",
      "         9262.8828,  8657.7793, 10848.9785,  8348.4375, 11050.3262,  9301.9580,\n",
      "         9211.8428, 10449.2207,  9181.8633,  9675.6543, 10520.4590,  8347.9336,\n",
      "         8692.1680,  9719.9336,  9292.6621, 11178.3975,  8318.8174,  9255.6455,\n",
      "         9154.0967,  9178.7773,  8913.3818,  9255.4316], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor(9491.9941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "train Loss: 0.3302 Acc: 0.0000\n",
      "tensor([ 8295.1152,  9308.5859,  8788.9961,  9690.4395, 10905.9727,  8927.2285,\n",
      "         8768.8574,  9000.6758,  8905.5352, 11608.0674,  8860.3906,  8183.0811,\n",
      "         8994.7363,  7649.9995, 11583.8750,  9315.2256,  8245.8203,  7396.4375,\n",
      "        11567.1963, 11335.0625,  8145.2202, 11888.8057,  7852.0098,  9043.6318,\n",
      "         8572.5186,  8013.7861, 11330.8242, 11685.0996,  8593.4902, 11213.5801,\n",
      "         8590.0801,  8314.3047,  8908.8008, 11052.1250,  8834.0273,  8707.7412,\n",
      "        11434.8223, 11120.1523,  7966.4531,  8799.9189, 12230.2910,  7808.4058,\n",
      "         8759.6543,  8427.6006, 11046.3496,  8317.1543, 11435.6514,  8848.6377,\n",
      "         8892.7529, 10444.9512,  8947.9033,  9463.8652, 10831.5957,  7453.7231,\n",
      "         8548.2090,  9412.7344,  8915.2070, 11773.4160,  8008.4277,  8885.5674,\n",
      "         8662.0879,  8763.6211,  8467.8320,  9139.7451], device='cuda:0')\n",
      "tensor(9388.8135, device='cuda:0')\n",
      "val Loss: 3.0058 Acc: 0.0000\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "tensor([ 8349.3926,  9839.0195,  9189.6816,  9888.9561, 10280.3516,  9559.8760,\n",
      "         9465.2656,  9536.2480,  9134.6504, 10817.1426,  9307.0547,  8327.6992,\n",
      "         9213.7207,  8362.6523, 11068.2793,  8923.5889,  8381.6895,  8332.6406,\n",
      "        11155.9102, 10782.3770,  8432.5703, 11190.1572,  8315.2979,  9517.9375,\n",
      "         9135.4424,  8321.2900, 11015.0879, 10852.1562,  8407.2598, 10764.4912,\n",
      "         8533.8096,  9271.5254,  9279.8145, 10490.0293,  8803.1387,  9272.5254,\n",
      "        10998.5791, 10858.8643,  8337.2393,  8973.7168, 10766.7061,  8329.7383,\n",
      "         9229.7617,  8682.3076, 10788.5273,  8358.5938, 11074.5898,  9261.4863,\n",
      "         9156.5312, 10447.3682,  9219.9258,  9635.5947, 10478.8359,  8356.1143,\n",
      "         8693.0596,  9740.7969,  9242.3516, 11165.9902,  8332.2109,  9250.4834,\n",
      "         9140.7793,  9166.0879,  8918.1201,  9307.8066], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor(9491.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "train Loss: 0.1008 Acc: 0.0000\n",
      "tensor([ 8239.1162,  9302.9990,  8719.4062,  8889.8770, 10777.2354,  9039.6992,\n",
      "         9242.9062,  8881.9932,  8917.4062, 11102.5957,  8934.8740,  7864.4443,\n",
      "         8851.9268,  7468.0586, 11848.0020,  9233.6406,  7996.8242,  7987.8047,\n",
      "        11586.7578, 11846.4941,  8263.0498, 12682.2617,  8085.7837,  8697.9834,\n",
      "         8516.3301,  8273.2637, 11473.7715, 11621.6523,  8689.9805, 12636.5508,\n",
      "         8714.8018,  8019.3779,  8752.8926, 10402.0332,  8859.3545,  9029.6465,\n",
      "        11838.8047, 10986.5449,  8228.4238,  8593.8711, 12260.7598,  8207.5293,\n",
      "         8863.7432,  8601.4980, 11299.8691,  8414.0781, 11688.8730,  9116.6406,\n",
      "         8740.1562, 10419.3047,  8639.9053,  8518.3066, 10405.4336,  7526.4131,\n",
      "         8542.2002,  9128.5840,  8881.0781, 12338.0234,  7998.2139,  7666.8374,\n",
      "         8407.3008,  8033.6128,  8301.6172,  9078.3564], device='cuda:0')\n",
      "tensor(9377.7617, device='cuda:0')\n",
      "val Loss: 6.2992 Acc: 0.0000\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "tensor([ 8352.9502,  9791.0117,  9210.1035,  9857.0713, 10267.0244,  9553.9082,\n",
      "         9490.8174,  9531.1484,  9158.1230, 10799.9453,  9297.5586,  8330.0645,\n",
      "         9203.8506,  8362.5244, 11109.0000,  8927.0996,  8385.4766,  8332.5859,\n",
      "        11151.2236, 10791.6279,  8433.4863, 11172.3721,  8316.6934,  9481.5869,\n",
      "         9120.4414,  8325.6406, 11003.4180, 10834.9404,  8401.4121, 10797.0869,\n",
      "         8538.4316,  9286.9570,  9307.0605, 10437.2656,  8800.5752,  9288.8887,\n",
      "        10974.2031, 10833.1240,  8340.9844,  8989.7227, 10768.6641,  8335.5527,\n",
      "         9223.9180,  8692.0684, 10800.1445,  8358.5000, 11052.1113,  9296.8223,\n",
      "         9170.8613, 10427.2119,  9187.4287,  9632.3887, 10461.6367,  8355.7402,\n",
      "         8712.5234,  9682.8457,  9278.4023, 11186.7080,  8332.3262,  9231.2197,\n",
      "         9116.8906,  9169.5332,  8915.4980,  9242.4648], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor(9487.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "train Loss: 0.0373 Acc: 0.0000\n",
      "tensor([ 8409.4004,  8828.4619,  8201.7988,  8667.3213, 11574.0469,  7740.6079,\n",
      "         7717.2656,  8608.6494,  8505.9531, 11470.3027,  8709.5020,  8218.3242,\n",
      "         8985.3291,  7795.0649, 11713.9619,  9154.2021,  7625.3311,  8030.9062,\n",
      "        11530.5918, 12237.4912,  8328.2822, 15604.1523,  7841.5493,  6637.3589,\n",
      "         5943.1357,  8206.6064, 11955.4805, 12680.5488,  8622.9238, 13251.7891,\n",
      "         8909.4902,  4880.2393,  7952.2715, 10316.7354,  8807.8662,  9045.0566,\n",
      "        12674.0293, 11729.3906,  8082.8330,  8437.6094, 15177.8643,  8097.8960,\n",
      "         8721.7471,  8638.9258, 11613.0020,  8271.2500, 11957.5938,  8561.4414,\n",
      "         8398.3027, 10483.5000,  8090.6357,  7571.6113, 10042.0156,  7854.8545,\n",
      "         8448.2520,  8238.4756,  8035.6562, 13618.5137,  8321.5488,  7174.9614,\n",
      "         7608.8154,  7339.5146,  7911.2510,  8759.9863], device='cuda:0')\n",
      "tensor(9258.8984, device='cuda:0')\n",
      "val Loss: 10.5273 Acc: 0.0156\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "tensor([ 8353.4297,  9786.7188,  9202.8535,  9853.3945, 10280.2402,  9535.1875,\n",
      "         9475.7676,  9533.2910,  9175.3154, 10802.0225,  9300.3164,  8328.8652,\n",
      "         9201.0820,  8360.7188, 11114.0625,  8931.4307,  8378.4199,  8326.7490,\n",
      "        11153.3770, 10796.0645,  8430.9775, 11176.1055,  8312.7500,  9467.6289,\n",
      "         9110.3770,  8321.8311, 11006.7012, 10841.8398,  8400.1230, 10806.1289,\n",
      "         8531.2676,  9283.1641,  9302.4355, 10442.1465,  8795.6201,  9278.2666,\n",
      "        10973.0576, 10839.8008,  8339.4609,  8991.7734, 10774.4629,  8330.5312,\n",
      "         9219.3652,  8695.0762, 10803.4590,  8355.0811, 11048.4443,  9301.1406,\n",
      "         9175.3408, 10411.0566,  9166.1543,  9628.6816, 10462.4092,  8358.9082,\n",
      "         8717.2500,  9681.7344,  9272.4688, 11189.7109,  8327.8281,  9233.5352,\n",
      "         9115.9375,  9165.8184,  8910.9062,  9246.1504], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor(9486.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "train Loss: 0.0363 Acc: 0.0000\n",
      "tensor([ 8332.5752,  8691.0752,  7690.0400,  9005.7461, 11700.7412,  7964.3569,\n",
      "         7765.2627,  8469.7803,  8442.6895, 11998.5811,  8799.7646,  7942.8335,\n",
      "         9245.3809,  7768.2349, 11509.3711,  9044.2012,  7502.6621,  7629.8018,\n",
      "        11359.0576, 11882.1660,  8185.6221, 14570.0078,  7463.0645,  8241.4492,\n",
      "         6473.5581,  8212.1143, 11742.9863, 12033.3906,  8563.4668, 12305.7178,\n",
      "         8635.5176,  6648.8647,  8043.1367, 10472.7285,  8749.8076,  7244.0264,\n",
      "        12831.1289, 12520.6641,  7720.3301,  8706.9238, 15473.7842,  7740.5547,\n",
      "         9073.7188,  8648.3369, 11499.0137,  8175.9517, 11719.7334,  8087.6846,\n",
      "         8375.2246, 10192.1406,  8223.4004,  8550.6250, 10142.4844,  7321.7578,\n",
      "         8628.5557,  8397.8428,  7411.3242, 12753.7588,  8022.5210,  8387.2637,\n",
      "         7733.0815,  7792.7432,  8374.0127,  9042.4521], device='cuda:0')\n",
      "tensor(9248.0752, device='cuda:0')\n",
      "val Loss: 14.7057 Acc: 0.0156\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "tensor([ 8348.9824,  9786.7529,  9191.3877,  9860.3887, 10285.9561,  9529.0264,\n",
      "         9462.4873,  9537.2900,  9174.4873, 10805.9531,  9297.6553,  8326.8779,\n",
      "         9206.0518,  8357.6738, 11112.6562,  8933.0010,  8370.7676,  8323.1543,\n",
      "        11152.4873, 10795.4717,  8426.7725, 11179.0498,  8311.4863,  9460.7334,\n",
      "         9105.5527,  8317.8789, 11007.7041, 10837.5518,  8398.3672, 10804.3828,\n",
      "         8525.5664,  9274.9902,  9293.1230, 10443.3906,  8794.9316,  9263.2119,\n",
      "        10979.1602, 10850.5449,  8335.4551,  8996.5176, 10778.1045,  8325.7217,\n",
      "         9212.9746,  8690.7695, 10801.8330,  8351.7773, 11048.3721,  9293.6299,\n",
      "         9173.4482, 10408.4629,  9158.7588,  9631.8359, 10469.8281,  8357.5732,\n",
      "         8718.6328,  9683.9053,  9259.3252, 11191.4043,  8323.4570,  9239.7656,\n",
      "         9110.1602,  9157.7832,  8905.3535,  9251.7383], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor(9484.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0361 Acc: 0.0000\n",
      "tensor([ 7994.0679,  9543.4453,  8847.4268,  9601.6035, 10789.4033,  9204.6953,\n",
      "         9108.9297,  9216.2432,  9031.2988, 11631.5918,  9060.8047,  7642.4971,\n",
      "         9051.2939,  7948.1748, 11418.9082,  8943.6396,  7433.8193,  7779.6475,\n",
      "        11339.2979, 11139.3652,  8181.4990, 12202.7715,  7793.4497,  9199.0801,\n",
      "         8595.6797,  7860.5864, 11317.6240, 11363.8770,  8214.3984, 11070.9795,\n",
      "         7959.1973,  8758.4102,  8921.7793, 10414.5762,  8834.5918,  8874.9004,\n",
      "        11230.1543, 11517.7100,  7723.1533,  8795.7520, 11819.5215,  7762.6396,\n",
      "         9031.2539,  8634.9121, 11055.3945,  8013.7129, 11383.9199,  9090.9473,\n",
      "         8885.6426, 10297.2031,  8733.5166,  9424.8027, 10535.3691,  7255.2129,\n",
      "         8561.5547,  9465.9746,  8682.1836, 11806.3945,  7426.3950,  8896.9707,\n",
      "         8701.8125,  8812.7715,  8774.9219,  9059.8770], device='cuda:0')\n",
      "tensor(9338.5820, device='cuda:0')\n",
      "val Loss: 14.7996 Acc: 0.0000\n",
      "\n",
      "Training complete in 0m 37s\n",
      "Best val Acc: 0.015625\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YNRIHl0JKEU3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef imshow(inp, title=None):\\n    #Imshow for Tensor\\n    inp = inp.numpy().transpose((1, 2, 0))\\n    mean = np.array([0.485, 0.456, 0.406])\\n    std = np.array([0.229, 0.224, 0.225])\\n    inp = std * inp + mean\\n    inp = np.clip(inp, 0, 1)\\n    plt.imshow(inp)\\n    if title is not None:\\n        plt.title(title)\\n    plt.pause(0.001)  # pause a bit so that plots are updated\\n\\n\\nfor idx, batch in enumerate(dataloaders[\"train\"]):\\n    # Convert images (input) to float because it is a ByteTensor. Why is it a ByteTensor?\\n    images, labels = batch[\"image\"].float(), batch[\"geohash\"].float()\\n    out = torchvision.utils.make_grid(images)\\n\\n    imshow(out)\\n    \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def imshow(inp, title=None):\n",
    "    #Imshow for Tensor\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "for idx, batch in enumerate(dataloaders[\"train\"]):\n",
    "    # Convert images (input) to float because it is a ByteTensor. Why is it a ByteTensor?\n",
    "    images, labels = batch[\"image\"].float(), batch[\"geohash\"].float()\n",
    "    out = torchvision.utils.make_grid(images)\n",
    "\n",
    "    imshow(out)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6NtC1_Y2n5ne"
   },
   "outputs": [],
   "source": [
    "t = torch.arange(10).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1672146064864,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "cJdia4OvrAuy",
    "outputId": "5bc919cf-d916-482b-ec9a-77d089dcdfb9"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "# model_ft = models.resnet18()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3139)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7GEvmhLTrCA6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\Users\\\\basti\\\\Documents\\\\Goethe Uni\\\\DLCV Projekt\\\\models\\\\pretrained.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbasti\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGoethe Uni\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDLCV Projekt\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpretrained.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model_ft\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m optimizer_ft\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\Users\\\\basti\\\\Documents\\\\Goethe Uni\\\\DLCV Projekt\\\\models\\\\pretrained.tar'"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = torch.load(r\"F:\\Users\\basti\\Documents\\Goethe Uni\\DLCV Projekt\\models\\pretrained.tar\")\n",
    "model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeohash\n",
    "def decimal_to_geohash(decimal):\n",
    "    base_32 = '0123456789bcdefghjkmnpqrstuvwxyz'\n",
    "    geohash = ''\n",
    "    while decimal > 0:\n",
    "        geohash += base_32[decimal % 32]\n",
    "        decimal //= 32\n",
    "    return geohash[::-1]\n",
    "\n",
    "def geohash_to_lat_lon(geohash):\n",
    "    return pygeohash.decode(geohash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "def geogussr_score(model):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    geogussrscore = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for idx, batch in enumerate(dataloaders['val']):\n",
    "        inputs, labels = batch[\"image\"], batch[\"geohash\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        _,labels = torch.max(labels, 1)\n",
    "\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        preds = geohashes_with_samples[preds.cpu()]\n",
    "        labels = geohashes_with_samples[labels.cpu()]\n",
    "\n",
    "        distance = []\n",
    "        if len(inputs) == 1:\n",
    "            distance.append(haversine(geohash_to_lat_lon(decimal_to_geohash(preds)),geohash_to_lat_lon(decimal_to_geohash(labels))))\n",
    "        else:\n",
    "            for i in range(len(inputs)):\n",
    "                distance.append(haversine(geohash_to_lat_lon(decimal_to_geohash(preds[i])),geohash_to_lat_lon(decimal_to_geohash(labels[i]))))\n",
    "           \n",
    "        \n",
    "        \n",
    "        geogussrscore.append((5000*np.exp(-np.array(distance)/2000)).mean())\n",
    "        \n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes['val']\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes['val']\n",
    "    average_score = np.array(geogussrscore).mean()\n",
    "    print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Score: {average_score:.4f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geogussr_score(model_ft)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUaWHSQQoRMwe+LN/u09r4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6b26721452f2d1ef6e818f0649f3a5fe6d15e71e413fd5aa88ad7acf81094b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
