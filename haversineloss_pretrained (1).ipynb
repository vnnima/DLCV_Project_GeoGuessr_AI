{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ot7HwUXrbvLP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Uni/Deep Learning for Computer Vision/GeoGuessr_Project')\n",
    "\n",
    "# folder with pictures\n",
    "ROOT_DIR = r'C:\\Users\\Shadow\\Pictures\\Geogussr\\Projekt'\n",
    "\n",
    "# dir to csv files\n",
    "dir = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\preprocess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N6AFTTy1w6-f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "#from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "# Dataset\n",
    "from GeoGuessrDataset import GeoGuessrDataset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tnrange\n",
    "import time\n",
    "import copy\n",
    "import pygeohash as phg\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable autoreloading of imported modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1672146399703,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "kj2xe7ZMKAs1",
    "outputId": "c81c3968-51d1-486d-f131-b8a171b62bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check GPU support on your machine.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "HEIGHT = 512\n",
    "WIDTH = 2560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1672147666496,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "YZytNzAjKDPf",
    "outputId": "8f6445df-cf8e-4b70-b414-11a1a81a29fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models.resnet import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights\n",
    "\n",
    "\n",
    "# New weights with accuracy 80.858%\n",
    "resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Best available weights (currently alias for IMAGENET1K_V2)\n",
    "# Note that these weights may change across versions\n",
    "resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1672147548946,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "Ob0MqD7HjcOD",
    "outputId": "550af3e4-a0bd-4353-d812-5f8d04873fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of geohashes with samples 3139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(dir+\"\\coordinates.csv\", delimiter=',', skiprows=0, low_memory=False)\n",
    "\n",
    "# We want a geohash precsion of 3 so that we get approximately 32768 cells, which will represent our classes.\n",
    "df['geohash']=df.apply(lambda coords: phg.encode(coords.latitude, coords.longitude, precision=3), axis=1)\n",
    "\n",
    "\n",
    "def geohash_to_decimal(geohash):\n",
    "    base_32 = '0123456789bcdefghjkmnpqrstuvwxyz';\n",
    "    geohash = geohash.lower()\n",
    "    # Check that the input geohash is a valid geohash\n",
    "    if not all(c in base_32 for c in geohash):\n",
    "        raise ValueError('Invalid geohash')\n",
    "    return sum([32**idx * base_32.index(char) for idx, char in enumerate(geohash[::-1])])\n",
    "\n",
    "df['geohash_decimal']=df.apply(lambda x: geohash_to_decimal(x[\"geohash\"]) ,axis=1)\n",
    "\n",
    "geohashes_with_samples = df[\"geohash_decimal\"].unique()\n",
    "print(\"Number of geohashes with samples\", len(geohashes_with_samples))\n",
    "\n",
    "geohash_map = { geo: i for i, geo in enumerate(geohashes_with_samples)}\n",
    "\n",
    "df[\"geo_code\"] = df.apply(lambda geohash: geohash_map[geohash[\"geohash_decimal\"]], axis=1)\n",
    "\n",
    "df[[\"filename\", \"latitude\",\"longitude\", \"geohash_decimal\", \"geo_code\"]].to_csv(dir+\"\\coordinates2.csv\", index=False)\n",
    "\n",
    "# Add geohash center coordinates to csv\n",
    "\n",
    "def geohash_center(geohash_name):\n",
    "\n",
    "    # Decode the geohash to get the center coordinates and errors.\n",
    "    latitude, longitude, latitude_error, longitude_error = phg.decode_exactly(geohash_name)\n",
    "    return [latitude, longitude]\n",
    "\n",
    "df[\"geo_lat\"], df[\"geo_lon\"] = df.apply(lambda x: geohash_center(x[\"geohash\"])[0] ,axis=1), df.apply(lambda x: geohash_center(x[\"geohash\"])[1] ,axis=1)\n",
    "\n",
    "# drop the duplicates\n",
    "df = df.drop(columns=[\"filename\", \"latitude\", \"longitude\",\"geohash_decimal\",\"geohash\"] )\n",
    "df = df.drop_duplicates()\n",
    "array = df.to_numpy()\n",
    "array = np.array(array, dtype=np.float64)\n",
    "tensor = torch.tensor(array)\n",
    "torch.save(tensor, dir+'\\\\tensor.pt')\n",
    "# Save the DataFrame to a CSV file.\n",
    "df[[\"geo_code\", \"geo_lat\", \"geo_lon\"]].to_csv(dir+\"\\coords_center.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1672147587577,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "bE4hyeKWKELu",
    "outputId": "4309c3f8-60cc-4217-b5a5-0d1dffee53c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103009\n",
      "torch.Size([8, 3, 250, 1000]) torch.Size([8, 3139]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "# Define the data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # normalize images\n",
    "    transforms.Resize((250, 1000))\n",
    "])\n",
    "\n",
    "# Load the dataset and split it into training and validation sets\n",
    "dataset = GeoGuessrDataset(csv_file=dir+'\\coordinates2.csv',\n",
    "                                    root_dir=ROOT_DIR, transform=transform, num_classes=3139)\n",
    "train_size = int(0.80 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "print(len(train_dataset))\n",
    "# Define the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=3)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=3)\n",
    "\n",
    "dataloaders = {\"train\" : train_dataloader, \"val\": val_dataloader}\n",
    "dataset_sizes = {\"train\": train_size, \"val\" : val_size}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    x, y, z = batch[\"image\"], batch[\"geohash\"], batch['gt']\n",
    "    print(x.shape, y.shape, z.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3yX0Ph7LKEO7"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    best_acc = 0.0\n",
    "     \n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    epoch_dist = []\n",
    "    \n",
    "    ######################\n",
    "    # single batch test\n",
    "    #batch=next(iter(dataloaders[\"train\"]))\n",
    "    \n",
    "    ##############################\n",
    "    for epoch in (pbar := tnrange(num_epochs)):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_dist = 0.0\n",
    "            # Iterate over data.\n",
    "            #for idx, batch in enumerate(dataloaders[phase]):\n",
    "            inputs, labels, gt = batch[\"image\"], batch[\"geohash\"], batch['gt']\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "                ##########################################################\n",
    "                # loss switch :\n",
    "                # first line Haversine + CE\n",
    "                #second line benchmark\n",
    "                # third line cross entropy\n",
    "                #either use line 1 or 3\n",
    "                #loss = criterion(outputs, gt, labels)\n",
    "\n",
    "                loss = criterion2(outputs, labels.float())\n",
    "\n",
    "                ##########################################################\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "            _,labels = torch.max(labels, 1)\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            #running_dist += criterion1(outputs, gt, labels).item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            ################################################\n",
    "            #adjust for single batch testing\n",
    "            #epoch_distance = running_dist / dataset_sizes[phase]\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            ###############################################################\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Dist: ')\n",
    "\n",
    "            \n",
    "                \n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            else:\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                \n",
    "             # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                PATH3 = r\"C:\\Users\\Shadow\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\models\\pretrainedresnet50_14epoch_Celoss.tar\"\n",
    "                torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'val_loss_history': val_loss_history,\n",
    "                'val_acc_history': val_acc_history,\n",
    "                'train_loss_history' : train_loss_history,\n",
    "                'train_acc_history' : train_acc_history\n",
    "                }, PATH3)\n",
    "\n",
    "        print()\n",
    "\n",
    "    \n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def haversine_loss(lons1, lats1, lons2, lats2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two sets of longitudes and latitudes.\n",
    "\n",
    "    Parameters:\n",
    "        - lons1 (torch.tensor): Tensor of longitudes for the first set of points.\n",
    "        - lats1 (torch.tensor): Tensor of latitudes for the first set of points.\n",
    "        - lons2 (torch.tensor): Tensor of longitudes for the second set of points.\n",
    "        - lats2 (torch.tensor): Tensor of latitudes\n",
    "\n",
    "    Returns:\n",
    "        - distances (torch.tensor): Tensor of Haversine distances.\n",
    "    \"\"\"\n",
    "    # Convert longitudes and latitudes to radians.\n",
    "    lons1 = lons1.to(torch.float) * math.pi / 180\n",
    "    lats1 = lats1.to(torch.float) * math.pi / 180\n",
    "    lons2 = lons2.to(torch.float) * math.pi / 180\n",
    "    lats2 = lats2.to(torch.float) * math.pi / 180\n",
    "\n",
    "    # Calculate differences in longitudes and latitudes.\n",
    "    dlons = lons2 - lons1\n",
    "    dlats = lats2 - lats1\n",
    "\n",
    "    # Calculate intermediate values.\n",
    "    a = (torch.sin(dlats / 2)**2) + (torch.cos(lats1) * torch.cos(lats2) * (torch.sin(dlons / 2)**2))\n",
    "    c = 2 * torch.atan2(torch.sqrt(a), torch.sqrt(1 - a))\n",
    "\n",
    "    # Calculate distances.\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    distances = R * c\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom loss that transforms the predicted cluster and the ground truth label into coordinates\n",
    "# and then computes the haversine distance between them as loss combined with cross entropy loss\n",
    "\n",
    "\n",
    "class HaversineLoss_CE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HaversineLoss_CE, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, output, gt, labels):\n",
    "        \"\"\"\n",
    "            output: (batchsize, num_clusters) Tensor with probabillities\n",
    "            gt: tupel contains groundtruth lat, lon\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        tensor = torch.load(dir+'\\\\tensor.pt')\n",
    "        # Extract the latitude and longitude from the predicted location.\n",
    "        #lat_cluster, lon_cluster = torch.zeros(len(output)), torch.zeros(len(output))\n",
    "        lat_cluster, lon_cluster = tensor[:,1], tensor[:,2]\n",
    "\n",
    "        # Calculate the Haversine distance between the predicted and target locations.\n",
    "        gt0 = torch.tensor(gt[:,0])\n",
    "        gt1 = torch.tensor(gt[:,1])\n",
    "        \n",
    "        distance = haversine_loss(lat_cluster, lon_cluster, gt0[:,None], gt1[:,None])\n",
    "        #print(torch.argmin(distance,dim=1))    \n",
    "        \n",
    "        \n",
    "        output1 = F.softmax(output, dim=1)\n",
    "        \n",
    "        # Return the loss.\n",
    "        distance = distance.to(device)\n",
    "        #print(torch.sum(distance*output,dim=1))\n",
    "        \n",
    "        loss = torch.mean(torch.sum(distance*output1,dim=1)) + 10000 * self.criterion(output, labels.float())\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used as another benchmark value\n",
    "\n",
    "\n",
    "\n",
    "class HaversineLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HaversineLoss, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, output, gt, labels):\n",
    "        \"\"\"\n",
    "            output: (batchsize, num_clusters) Tensor with probabillities\n",
    "            gt: tupel contains groundtruth lat, lon\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        tensor = torch.load(dir+'\\\\tensor.pt')\n",
    "        # Extract the latitude and longitude from the predicted location.\n",
    "        #lat_cluster, lon_cluster = torch.zeros(len(output)), torch.zeros(len(output))\n",
    "        lat_cluster, lon_cluster = tensor[:,1], tensor[:,2]\n",
    "\n",
    "        # Calculate the Haversine distance between the predicted and target locations.\n",
    "        gt0 = torch.tensor(gt[:,0])\n",
    "        gt1 = torch.tensor(gt[:,1])\n",
    "        \n",
    "        distance = haversine_loss(lat_cluster, lon_cluster, gt0[:,None], gt1[:,None])\n",
    "        #print(torch.argmin(distance,dim=1))    \n",
    "        \n",
    "        \n",
    "        output1 = F.softmax(output, dim=1)\n",
    "        \n",
    "        # Return the loss.\n",
    "        distance = distance.to(device)\n",
    "        #print(torch.sum(distance*output,dim=1))\n",
    "        \n",
    "        loss = torch.mean(torch.sum(distance*output1,dim=1)) #+ 10000 * self.criterion(output, labels.float())\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IVLjMMowKER4"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "# model_ft = models.resnet18()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3139)\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "\n",
    " \n",
    "criterion = HaversineLoss_CE()\n",
    "criterion1 = HaversineLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4792103,
     "status": "ok",
     "timestamp": 1672152510104,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "uPdTudKxnSoo",
    "outputId": "7f192f3b-35a2-495d-8033-6a2712be1716",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c501b63ee144d486e4a10e2e57b1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 8.0897 Acc: 0.0000 Dist: \n",
      "phase tensor(0., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "val Loss: 8.0423 Acc: 0.0000 Dist: \n",
      "phase tensor(0., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 7.6330 Acc: 0.6250 Dist: \n",
      "phase tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "val Loss: 7.9626 Acc: 0.0000 Dist: \n",
      "phase tensor(0., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 7.2121 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "val Loss: 7.8754 Acc: 0.0000 Dist: \n",
      "phase tensor(0., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 6.8192 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "val Loss: 7.7759 Acc: 0.0000 Dist: \n",
      "phase tensor(0., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 6.4266 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "val Loss: 7.6568 Acc: 0.3750 Dist: \n",
      "phase tensor(0.3750, device='cuda:0', dtype=torch.float64)\n",
      "acc 0.0\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 6.0321 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(0.3750, device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 7.5147 Acc: 0.7500 Dist: \n",
      "phase tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(0.3750, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 5.6411 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 7.3470 Acc: 0.8750 Dist: \n",
      "phase tensor(0.8750, device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 5.2524 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(0.8750, device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 7.2711 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(0.8750, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 5.2103 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 7.1891 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 5.1641 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 7.1024 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 5.1159 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 7.0063 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 5.0668 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 6.9036 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 5.0176 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 6.7962 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 4.9680 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "val Loss: 6.6922 Acc: 1.0000 Dist: \n",
      "phase tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "acc tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Best val Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1672146064864,
     "user": {
      "displayName": "Valdrin N.",
      "userId": "09743048349439752920"
     },
     "user_tz": -60
    },
    "id": "cJdia4OvrAuy",
    "outputId": "5bc919cf-d916-482b-ec9a-77d089dcdfb9"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "# model_ft = models.resnet18()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3139)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7GEvmhLTrCA6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\Users\\\\basti\\\\Documents\\\\Goethe Uni\\\\DLCV Projekt\\\\models\\\\pretrained.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbasti\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGoethe Uni\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDLCV Projekt\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpretrained.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model_ft\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m optimizer_ft\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\Users\\\\basti\\\\Documents\\\\Goethe Uni\\\\DLCV Projekt\\\\models\\\\pretrained.tar'"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = torch.load(r\"F:\\Users\\basti\\Documents\\Goethe Uni\\DLCV Projekt\\models\\pretrained.tar\")\n",
    "model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeohash\n",
    "def decimal_to_geohash(decimal):\n",
    "    base_32 = '0123456789bcdefghjkmnpqrstuvwxyz'\n",
    "    geohash = ''\n",
    "    while decimal > 0:\n",
    "        geohash += base_32[decimal % 32]\n",
    "        decimal //= 32\n",
    "    return geohash[::-1]\n",
    "\n",
    "def geohash_to_lat_lon(geohash):\n",
    "    return pygeohash.decode(geohash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "def geogussr_score(model):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    geogussrscore = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for idx, batch in enumerate(dataloaders['val']):\n",
    "        inputs, labels = batch[\"image\"], batch[\"geohash\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        _,labels = torch.max(labels, 1)\n",
    "\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        preds = geohashes_with_samples[preds.cpu()]\n",
    "        labels = geohashes_with_samples[labels.cpu()]\n",
    "\n",
    "        distance = []\n",
    "        if len(inputs) == 1:\n",
    "            distance.append(haversine(geohash_to_lat_lon(decimal_to_geohash(preds)),geohash_to_lat_lon(decimal_to_geohash(labels))))\n",
    "        else:\n",
    "            for i in range(len(inputs)):\n",
    "                distance.append(haversine(geohash_to_lat_lon(decimal_to_geohash(preds[i])),geohash_to_lat_lon(decimal_to_geohash(labels[i]))))\n",
    "           \n",
    "        \n",
    "        \n",
    "        geogussrscore.append((5000*np.exp(-np.array(distance)/2000)).mean())\n",
    "        \n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes['val']\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes['val']\n",
    "    average_score = np.array(geogussrscore).mean()\n",
    "    print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Score: {average_score:.4f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geogussr_score(model_ft)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUaWHSQQoRMwe+LN/u09r4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6b26721452f2d1ef6e818f0649f3a5fe6d15e71e413fd5aa88ad7acf81094b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
