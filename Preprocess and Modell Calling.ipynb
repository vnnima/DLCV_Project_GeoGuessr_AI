{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3df98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans2, whiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a0bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreloading of imported modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b071939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon(rel_path_to_images):\n",
    "    \"\"\"\n",
    "    Extracts lat and lon from image name and store them in array\n",
    "    !! Co-ordinates are saved as [Lon, Lat] !!\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of all filenames (insert path as string)\n",
    "    file_names = os.listdir(rel_path_to_images)\n",
    "\n",
    "    # strip everything but the coordinates and split lattitude and longitude\n",
    "    coord = [i[4:-4] for i in file_names]\n",
    "\n",
    "    # split to get lat and long and change type to np array \n",
    "    labels = np.array([np.array(i.split(\",\"), dtype = float) for i in coord])\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eab5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo: Find optimal k (use Elbow Method?)\n",
    "# Different outputs here because i was playing around with formats for the dataloader and thought\n",
    "# we could eventually use those later\n",
    "\n",
    "def get_clusters(labels, k):\n",
    "\n",
    "    \"\"\"\n",
    "    Create k clusters and assign a cluster to each sample\n",
    "        \n",
    "        Returns:\n",
    "        labels = array shape N*3 of sample co-ordinates with their respective cluster\n",
    "        label_location: Dict that contains the center co-ordinates of each cluster\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    x, y = kmeans2(labels, k, iter = 20)  \n",
    "    labels = np.hstack((labels, y[:, np.newaxis]))\n",
    "    \n",
    "    # create dict to map class to co-ordinates for final prediction\n",
    "    keys = np.arange(len(x))\n",
    "    label_location = {keys[i]:x[i] for i in range(len(x))}\n",
    "    \n",
    "    return labels, label_location, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bef7445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataloader\n",
    "# in the NN we would only predict classes, not yet coordinates. This allows y to be one number per sample\n",
    "# This can later be changed, just seemed more convenient to me\n",
    "\n",
    "class GeoGuessrData(Dataset):\n",
    "    \n",
    "    def __init__(self, y, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        y(array): array shape N with clusternames\n",
    "        root_dir(string): Directory with all the images\n",
    "        transform: As we wonÂ´t need to resize anything we just transform array-->tensor\n",
    "        \"\"\"\n",
    "        self.y = y\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"support the indexing such that dataset[i] can be used to get ith sample\"\"\"\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # get image by path and idx\n",
    "        img_name = os.listdir(self.root_dir)[idx]\n",
    "        image = io.imread(os.path.join(self.root_dir, img_name))\n",
    "        sample = {\"image\": image, \"cluster\": self.y[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        # get len of dataset\n",
    "        return len(self.y)\n",
    "    \n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, cluster = sample['image'], sample['cluster']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        # not 100% sure if transforming y is of any use yet\n",
    "        return {'image': torch.from_numpy(image).float(),\n",
    "                'cluster': torch.from_numpy(np.array(cluster)).float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ad6de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "# load dataset for dataloader\n",
    "labels = get_lat_lon(r\"F:\\Users\\basti\\Projekt\")\n",
    "labels, label_location, y = get_clusters(labels, 100)\n",
    "dataset = GeoGuessrData(y, r\"F:\\Users\\basti\\Projekt\", transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f608147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(dataset)\n",
    "train_size = int(size*0.8)\n",
    "test_size = (size - train_size) //2\n",
    "validation_size = (size - train_size) //2 +1\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset,\n",
    "                                               [train_size, validation_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f417a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3abd620de48568f181951b28cfa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6320/3850802023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Adam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\Users\\basti\\Documents\\Goethe Uni\\DLCV Projekt\\solver.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, num_epochs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m#self.model.train()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from networks import ResNet\n",
    "from solver import Solver\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model=ResNet()\n",
    "solver = Solver(model,{'train':test_dataset,'val':validation_dataset},optimizer=\"Adam\",optimizer_config={'weight_decay':True})\n",
    "history =solver.train(num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_training\n",
    "show_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "789d720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "#del variables\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6b26721452f2d1ef6e818f0649f3a5fe6d15e71e413fd5aa88ad7acf81094b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
