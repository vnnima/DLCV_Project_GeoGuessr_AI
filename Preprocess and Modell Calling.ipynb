{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3df98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans2, whiten\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a0bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreloading of imported modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8d5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b071939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon(rel_path_to_images):\n",
    "    \"\"\"\n",
    "    Extracts lat and lon from image name and store them in array\n",
    "    !! Co-ordinates are saved as [Lon, Lat] !!\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of all filenames (insert path as string)\n",
    "    file_names = os.listdir(rel_path_to_images)\n",
    "\n",
    "    # strip everything but the coordinates and split lattitude and longitude\n",
    "    coord = [i[4:-4] for i in file_names]\n",
    "\n",
    "    # split to get lat and long and change type to np array \n",
    "    labels = np.array([np.array(i.split(\",\"), dtype = float) for i in coord])\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eab5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo: Find optimal k (use Elbow Method?)\n",
    "# Different outputs here because i was playing around with formats for the dataloader and thought\n",
    "# we could eventually use those later\n",
    "\n",
    "def get_clusters(labels, k):\n",
    "\n",
    "    \"\"\"\n",
    "    Create k clusters and assign a cluster to each sample\n",
    "        \n",
    "        Returns:\n",
    "        labels = array shape N*3 of sample co-ordinates with their respective cluster\n",
    "        label_location: Dict that contains the center co-ordinates of each cluster\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    x, y = kmeans2(labels, k, iter = 20)  \n",
    "    labels = np.hstack((labels, y[:, np.newaxis]))\n",
    "    \n",
    "    # create dict to map class to co-ordinates for final prediction\n",
    "    keys = np.arange(len(x))\n",
    "    label_location = {keys[i]:x[i] for i in range(len(x))}\n",
    "    \n",
    "    return labels, label_location, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef7445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataloader\n",
    "# in the NN we would only predict classes, not yet coordinates. This allows y to be one number per sample\n",
    "# This can later be changed, just seemed more convenient to me\n",
    "\n",
    "class GeoGuessrData(Dataset):\n",
    "    \n",
    "    def __init__(self, y, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        y(array): array shape N with clusternames\n",
    "        root_dir(string): Directory with all the images\n",
    "        transform: As we wonÂ´t need to resize anything we just transform array-->tensor\n",
    "        \"\"\"\n",
    "        self.y = y\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"support the indexing such that dataset[i] can be used to get ith sample\"\"\"\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # get image by path and idx\n",
    "        img_name = os.listdir(self.root_dir)[idx]\n",
    "        image = io.imread(os.path.join(self.root_dir, img_name))\n",
    "        sample = {\"image\": image, \"cluster\": self.y[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample[\"image\"] = self.transform(sample[\"image\"])\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        # get len of dataset\n",
    "        return len(self.y)\n",
    "    \n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, cluster = sample['image'], sample['cluster']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        # not 100% sure if transforming y is of any use yet\n",
    "        return {'image': torch.from_numpy(image).float(),\n",
    "                'cluster': torch.from_numpy(np.array(cluster)).float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad6de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\.conda\\envs\\pytorch\\lib\\site-packages\\scipy\\cluster\\vq.py:603: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "# load dataset for dataloader\n",
    "labels = get_lat_lon(r\"C:\\Users\\Shadow\\Pictures\\Geogussr\\Projekt\")\n",
    "labels, label_location, y = get_clusters(labels, 100)\n",
    "dataset = GeoGuessrData(y, r\"C:\\Users\\Shadow\\Pictures\\Geogussr\\Projekt\", transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f608147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(dataset)\n",
    "train_size = int(size*0.8)\n",
    "test_size = (size - train_size) //2\n",
    "validation_size = (size - train_size) //2 +1\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset,\n",
    "                                               [train_size, validation_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20278e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import ResNet\n",
    "from networks import GeoGuessrNet\n",
    "\n",
    "HEIGHT = 512\n",
    "WIDTH = 2560\n",
    "\n",
    "model=GeoGuessrNet()\n",
    "#summary(model, (3,HEIGHT, WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f417a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "train, we are stuck\n",
      "train, we are not stuck!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100a33ba655d4d798ad84d572c7e0286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh sole mio\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "test, we are stuck\n",
      "test, we are not stuck!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m      5\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(model,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:test_dataset,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m:validation_dataset},optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m,optimizer_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\solver.py:285\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self, num_epochs)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(loss_history)\u001b[38;5;241m/\u001b[39mi)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m#see training accuracy and store it\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_train_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_acc\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m#see validation accuracy and store it\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\DLCV_Project_GeoGuessr_AI-Basti\\solver.py:196\u001b[0m, in \u001b[0;36mSolver.test\u001b[1;34m(self, dataset, num_samples)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m#treat labels ands inputs seperatly \u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;66;03m#put relevant stuff to cuda (if available)\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    197\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m#compute forward pass\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\n",
    "from solver import Solver\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "solver = Solver(model,{'train':test_dataset,'val':validation_dataset},optimizer=\"Adam\",optimizer_config={'weight_decay':True})\n",
    "history =solver.train(num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e139aff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_training\n\u001b[1;32m----> 2\u001b[0m show_training(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import show_training\n",
    "show_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "#del variables\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb915610",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "            self.data_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True          \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30574c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f246b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6b26721452f2d1ef6e818f0649f3a5fe6d15e71e413fd5aa88ad7acf81094b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
